{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8:\n",
    "    \"\"\"\n",
    "    Модель YOLO, преобразованная в onnx формат\n",
    "    \"\"\"\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5):\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "\n",
    "        # Инициализация модели\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.detect_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        \"\"\"\n",
    "        Инициализация модели\n",
    "        \n",
    "        :param path: путь к модели\n",
    "        \"\"\"\n",
    "        # Основной класс для запуска модели\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=['CUDAExecutionProvider',\n",
    "                                                               'CPUExecutionProvider'])\n",
    "        # Получение информации о модели\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        \"\"\"\n",
    "        Детекция изображения\n",
    "        \n",
    "        :param image: np.array - прочитанное изображение в массив\n",
    "        \"\"\"\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Результат предикции\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids = self.process_output(outputs)\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        \"\"\"\n",
    "        Подготавливает изображение\n",
    "        \n",
    "        :param image: np.array - прочитанное изображение в массив\n",
    "        \"\"\"\n",
    "        self.img_height, self.img_width = image.shape[:2]\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Ресайз изображения\n",
    "        image = cv2.resize(image, (640, 640), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Скалирование изображения\n",
    "        image = image / 255.0\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        input_tensor = image[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Инференс модели\n",
    "        \n",
    "        :param input_tensor: np.array - подготовленное изображение\n",
    "        \"\"\"\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_output(self, output):\n",
    "        \"\"\"\n",
    "        Подготовка результатов модели\n",
    "        \"\"\"\n",
    "        predictions = np.squeeze(output[0]).T\n",
    "\n",
    "        # Фильтрафия оценок, которые ниже уверенности модели\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        # Класс с наибольшей уверенностью\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Прямоугольники для каждого предсказания\n",
    "        self.extract_boxes(predictions)\n",
    "\n",
    "        # Применение метода nms\n",
    "        indices = nms(self.boxes, scores, self.iou_threshold)\n",
    "\n",
    "        return self.boxes[indices], scores[indices], class_ids[indices]\n",
    "\n",
    "    def extract_boxes(self, predictions):\n",
    "        \"\"\"\n",
    "        Извлечение прямоугольников\n",
    "        \"\"\"\n",
    "        # Прямоугольники\n",
    "        self.boxes = predictions[:, :4]\n",
    "        # Рескалинг под разрешение изображения\n",
    "        self.boxes = self.rescale_boxes(self.boxes)\n",
    "        # Перевод в формат vol\n",
    "        self.boxes = xywh2xyxy(self.boxes)\n",
    "        \n",
    "\n",
    "    def get_boxes(self):\n",
    "        \"\"\"\n",
    "        Получить прямоугольники из экземпляра класса\n",
    "        \"\"\"\n",
    "        return self.boxes\n",
    "\n",
    "    def rescale_boxes(self, boxes):\n",
    "        \"\"\"\n",
    "        Рескейл к исходному разрешению\n",
    "        \"\"\"\n",
    "        input_shape = np.array([self.input_width, self.input_height,\n",
    "                                self.input_width, self.input_height])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([self.img_width, self.img_height, self.img_width, self.img_height])\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image):\n",
    "        \"\"\"\n",
    "        Нанесение прямоугольников\n",
    "        \"\"\"\n",
    "        class_names = ['Cable_drum']\n",
    "        rng = np.random.default_rng(3)\n",
    "        colors = rng.uniform(0, 255, size=(len(class_names), 3))\n",
    "        \n",
    "        # Прямоугольники\n",
    "        for box, score, class_id in zip(self.boxes, self.scores, self.class_ids):\n",
    "            color = colors[class_id]\n",
    "\n",
    "            x_1, y_1, x_2, y_2 = box.astype(int)\n",
    "\n",
    "            # Прямоугольник\n",
    "            cv2.rectangle(image, (x_1, y_1), (x_2, y_2), color, 2)\n",
    "\n",
    "            # Отображение лейблов\n",
    "            label = class_names[class_id]\n",
    "            caption = f'{label} {int(score * 100)}%'\n",
    "                    \n",
    "            # font\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    \n",
    "            # fontScale\n",
    "            fontScale = 1\n",
    "            \n",
    "            # Line thickness of 2 px\n",
    "            thickness = 2\n",
    "            \n",
    "            # Using cv2.putText() method\n",
    "            cv2.putText(image, caption, (x_1, y_1 - 4 * thickness),\n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)        \n",
    "\n",
    "        return image\n",
    "\n",
    "    def get_input_details(self):\n",
    "        \"\"\"\n",
    "        Получение информации из входных данных\n",
    "        \"\"\"\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        \"\"\"\n",
    "        Информация о выходных значениях\n",
    "        \"\"\"\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
    "\n",
    "\n",
    "def nms(boxes, scores, iou_threshold):\n",
    "    \"\"\"\n",
    "    Алгоритм nms для удаления дублирующихся рамок\n",
    "    \"\"\"\n",
    "    # Сортировка по значению предсказания\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Выбор последнего прямоугольника\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Вычисление метрики по сравнению с остальными\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Выбор боксов, у которых метрика не превышает порога\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes):\n",
    "    \"\"\"\n",
    "    Вычисление iou\n",
    "    \"\"\"\n",
    "    # Выбор минимальных/максимальных значений\n",
    "    xmin = np.maximum(box[0], boxes[:, 0])\n",
    "    ymin = np.maximum(box[1], boxes[:, 1])\n",
    "    xmax = np.minimum(box[2], boxes[:, 2])\n",
    "    ymax = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # Вычисление площади пересечения\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Площадь объединения\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Расчет IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    \"\"\"\n",
    "    Конвертация формата рамок из YOLO в VOC\n",
    "    \"\"\"\n",
    "    # Конвертация (x, y, w, h) в (x1, y1, x2, y2)\n",
    "    # Из yolo формата в VOC\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_detect_image(image_path : str):\n",
    "    \"\"\"\n",
    "    Запуск модели\n",
    "    \"\"\"\n",
    "    # model_path = r'train4\\weights\\best.onnx'\n",
    "                \n",
    "    try:\n",
    "        model_path = r'./train5/weights/best.onnx'\n",
    "\n",
    "        yolov8_detector = YOLOv8(path=model_path,\n",
    "                                conf_thres=0.3,\n",
    "                                iou_thres=0.5)\n",
    "    \n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        yolov8_detector(img)\n",
    "        detected_img = yolov8_detector.draw_detections(img)\n",
    "        \n",
    "        # plt.imshow(cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        cv2.namedWindow(\"Output\", cv2.WINDOW_NORMAL)    \n",
    "        cv2.imshow(\"Output\", img)    \n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as error:\n",
    "    # handle the exception\n",
    "        print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "\n",
    "\n",
    "def onnx_detect_video():\n",
    "    \"\"\"\n",
    "    Запуск модели\n",
    "    \"\"\"\n",
    "    # Захват видео с камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # model_path = r'train4\\weights\\best.onnx'\n",
    "    model_path = r'./train4/weights/best.onnx'\n",
    "    \n",
    "    yolov8_detector = YOLOv8(path=model_path,\n",
    "                             conf_thres=0.3,\n",
    "                             iou_thres=0.5)\n",
    "\n",
    "    cv2.namedWindow(\"Detected Objects\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Кадр с камеры\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Детектирование\n",
    "        yolov8_detector(frame)\n",
    "        detected_img = yolov8_detector.draw_detections(frame)\n",
    "\n",
    "        # plt.imshow(cv2.cvtColor(detected_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        cv2.imshow(\"Detected Objects\", detected_img)\n",
    "\n",
    "        # Для выхода нажать q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_detect_empty_place():\n",
    "    \"\"\"\n",
    "    Запуск модели\n",
    "    \"\"\"\n",
    "    # Захват видео с камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    model_path = r'./train5/weights/best.onnx'\n",
    "    yolov8_detector = YOLOv8(path=model_path,\n",
    "                             conf_thres=0.3,\n",
    "                             iou_thres=0.5)\n",
    "\n",
    "    cv2.namedWindow(\"Detected Objects\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Местоположение парковочных мест\n",
    "    parked_drums_boxes = None\n",
    "    # Сколько кадров подряд с пустым местом мы уже видели\n",
    "    free_space_frames = 0\n",
    "    # Пустые места\n",
    "    free_space_boxes = None\n",
    "    \n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Кадр с камеры\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Детектирование\n",
    "        yolov8_detector(frame)\n",
    "        detected_img = yolov8_detector.draw_detections(frame)        \n",
    "\n",
    "        if parked_drums_boxes is None:\n",
    "            parked_drums_boxes = yolov8_detector.get_boxes()            \n",
    "        else:\n",
    "            # Если новая катушка >\n",
    "            # Если катушка только попала в кадр =\n",
    "            if len(yolov8_detector.get_boxes()) >= len(parked_drums_boxes):\n",
    "                parked_drums_boxes = yolov8_detector.get_boxes()\n",
    "\n",
    "            all_spaces_free = False\n",
    "\n",
    "            drums_boxes = yolov8_detector.get_boxes()\n",
    "            ## Если ни одна катушка не найдена, то только нарисовать пустые места\n",
    "            if (drums_boxes is None) or (len(drums_boxes) == 0):\n",
    "                if free_space_boxes is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    all_spaces_free = True\n",
    "                    # free_space_boxes = parked_drums_boxes\n",
    "\n",
    "            if not(all_spaces_free):\n",
    "                # Если только 1 катушка, то чтобы не лобалось IoU\n",
    "                if drums_boxes.shape[0] == 1:\n",
    "                    # drums_boxes = np.array([drums_boxes])\n",
    "                    drums_boxes = np.array(drums_boxes).reshape(1, -1)\n",
    "\n",
    "                # list с координатами пустых мест\n",
    "                free_space_boxes = []\n",
    "                # free_space = len(parked_drums_boxes) * [False]\n",
    "\n",
    "                for i in range(len(parked_drums_boxes)):\n",
    "                    IoUs = compute_iou(parked_drums_boxes[i], drums_boxes)\n",
    "                    max_IoU = np.max(IoUs)\n",
    "                    if max_IoU < 0.15:\n",
    "                        # Отмечаем, что мы нашли как минимум оно свободное место.\n",
    "                        # free_space[i] = True\n",
    "                        free_space_boxes.append(parked_drums_boxes[i].astype('int')) \n",
    "                \n",
    "            # Зелёные рамки вокруг пустых мест.                \n",
    "            for free_space_box in free_space_boxes:\n",
    "                x1, y1, x2, y2 = free_space_box\n",
    "\n",
    "                # Зелёная рамка\n",
    "                cv2.rectangle(detected_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Отображаем надпись Empty place\n",
    "                # font\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        \n",
    "                # fontScale\n",
    "                fontScale = 1\n",
    "                \n",
    "                # Line thickness of 2 px\n",
    "                thickness = 2\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(detected_img, f\"Empty place\", (x1, y1 - 4 * thickness),\n",
    "                            font, fontScale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Detected Objects\", detected_img)\n",
    "\n",
    "        # Для выхода нажать q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap = None\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    \n",
    "    cap = None\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "onnx_detect_empty_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_detect_image('/home/pc/ML/e6dfa34c-photo_2023-09-12_15-56-44.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
